{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSIGNA 1:\n",
    "\n",
    "**_1) Cargamos los datos_**\n",
    "- Carguen el dataset:\n",
    "```\n",
    "  data = pd.read_csv(\"encuesta-anual-hogares-2019.csv\", sep=',') \n",
    "```\n",
    "**_2) Inspecci칩n inicial_**\n",
    "- Eliminen las columnas `id` y `hijos_nacidos_vivos`\n",
    "\n",
    "**_3) Discretizaci칩n_**\n",
    "- Para las siguientes columnas discreticen por igual frecuencia e igual rango.\n",
    "    <br>`ingresos_familiares` con q=8\n",
    "    <br>`ingreso_per_capita_familiar` con q=10\n",
    "\n",
    "- En algunas situaciones hay ciertos elementos que se repiten al momento de discretizar, una forma de eliminar duplicados es con el argumento `duplicates='drop'`.\n",
    "    <br><br>Para las siguientes columnas `ingreso_total_lab` y `ingreso_total_no_lab` consideren:\n",
    "    ```\n",
    "    data['ingreso_total_lab'] = pd.qcut(data['ingreso_total_lab'], q=10, duplicates='drop')\n",
    "    data['ingreso_total_no_lab'] = pd.qcut(data['ingreso_total_no_lab'], q=4, duplicates='drop')\n",
    "    ```\n",
    "\n",
    "- Para la columna `edad` discreticen usando igual distancia con `bins=5`.\n",
    "\n",
    "**_4) Preparaci칩n de datos_**\n",
    "- Cambien el tipo de dato a `str` de las siguientes columnas: `comuna` y `nhogar`.\n",
    "  <br>_쯇or qu칠 hacemos esto?_ Para estas columnas el n칰mero es simplemente una connotaci칩n, para representar una comuna por ejemplo pero no hay una relaci칩n num칠rica entre ellos.\n",
    "\n",
    "- _쯈u칠 esperas como valor en la columna `a침os_escolaridad`?_ N칰mero enteros pero no siempre es as칤, cada entidad o empresa tiene diferentes formas de rellenar una encuesta.\n",
    "    <br>Evalua lo siguiente: `data['a침os_escolaridad'].unique()`, vas a poder ver los valores 칰nicos en la columna. Donde destacamos que todos son `object/string`.\n",
    "\n",
    "- Reemplazar `Ningun a침o de escolaridad aprobado` por un '0'. \n",
    "<br>Efectivamente por '0' y no 0, porque esta columna maneja datos tipo `object/string`.\n",
    "    ```\n",
    "    data['a침os_escolaridad'] = data['a침os_escolaridad'].replace('Ningun a침o de escolaridad aprobado', '0')\n",
    "    ```\n",
    "\n",
    "- Vamos a convertir los tipos de datos de la columna anterior `a침os_escolaridad` a enteros.\n",
    "    <br>De manera intuitiva podr칤amos hacer:\n",
    "    ```\n",
    "    data['a침os_escolaridad'] = data['a침os_escolaridad'].astype(float).astype(\"Int32\")\n",
    "    ```\n",
    "    PEROOOOOOO marca un error, 쯖ierto?\n",
    "    \n",
    "    Posiblemente muchas veces les pase que cuando hagan una _cast_ (conversi칩n de un tipo de dato a otro) pueden llegar a tener conflictos si esa columna tienen _NaN_. Para este caso si queremos convertir los valores de la columna `a침os_escolaridad` de _string_ a _int_, hay que hacer un paso intermedio que es pasarlo a _float_.\n",
    "    ```\n",
    "    data['a침os_escolaridad'] = data['a침os_escolaridad'].astype(float).astype(\"Int32\")\n",
    "    ```\n",
    "\n",
    "- Discreticen para la columna `a침os_escolaridad` por igual frecuencia e igual rango con un `q=5`\n",
    "\n",
    "- No necesariamente siempre hay que rellenar los `NaN` en todas las columnas, porque quiz치s esa cantidad de `NaN` no es tan representativa para nuestro an치lisis. As칤 que podes eliminarlo para todo el dataframe o para ciertas columnas.\n",
    "    ```\n",
    "    # Eliminar filas que contengan NaN\n",
    "    data = data.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])\n",
    "    ```\n",
    "- Despu칠s de eliminar filas, podes resetear el 칤ndice para que mantenga la secuencia:\n",
    "    ```\n",
    "    data = data.reset_index(drop=True)\n",
    "    ```\n",
    "\n",
    "- Rellenar los datos faltantes para la columna `a침os_escolaridad`. Primero a침adan la categor칤a `desconocido` y luego hacen un rellenado de los datos faltantes con `desconocido`.\n",
    "\n",
    "- Rellenar los datos faltantes para la columna `nivel_max_educativo` con `value=desconocido`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from funpymodeling.exploratory import freq_tbl, status, profiling_num\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data = pd.read_csv(\"./data/encuesta-anual-hogares-2019.csv\", sep=\",\", encoding='ISO-8859-1') \n",
    "data_original = data.copy()\n",
    "\n",
    "data.drop(['id', 'hijos_nacidos_vivos'], axis=1, inplace=True)\n",
    "\n",
    "status(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ingresos_familiares'], seved_bins_ingresos_familiares = pd.qcut(data['ingresos_familiares'], q=8, retbins=True)\n",
    "data['ingreso_per_capita_familiar'], seved_bins_ingresos_familiares = pd.qcut(data['ingreso_per_capita_familiar'], q=8, retbins=True)\n",
    "data['edad'], saved_bins_age = pd.cut(data['edad'], bins=5, retbins=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ingreso_total_lab'] = pd.qcut(data['ingreso_total_lab'], q=10, duplicates='drop')\n",
    "data['ingreso_total_no_lab'] = pd.qcut(data['ingreso_total_no_lab'], q=4, duplicates='drop')\n",
    "\n",
    "freq_tbl(data['ingreso_total_no_lab'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comuna'] = data['comuna'].astype(str)\n",
    "data['nhogar'] = data['nhogar'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(\"Ningun a침o de escolaridad aprobado\", \"0\", inplace=True)\n",
    "data['a침os_escolaridad'] = data['a침os_escolaridad'].astype(float).astype('Int16')\n",
    "data['a침os_escolaridad'].fillna(0, inplace=True)\n",
    "data['a침os_escolaridad'], saved_bins_anos_escolaridad = pd.qcut(data['a침os_escolaridad'], q=5, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['nivel_max_educativo'] = data['nivel_max_educativo'].astype('category')\n",
    "data['nivel_max_educativo'] = data['nivel_max_educativo'].cat.add_categories('desconocido')\n",
    "data['nivel_max_educativo'].fillna('desconocido', inplace=True)\n",
    "\n",
    "status(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONSIGNA 2:\n",
    "\n",
    "**_5) One hot encoding_**\n",
    "\n",
    "- Hagan `data_ohe = pd.get_dummies(data)`\n",
    "- Guardar `data_ohe` en un archivo pickle como vimos en clase con el nombre `categories_ohe.pickle`.\n",
    "- Carguen el dataset `new_data = pd.read_csv(\"new_data.csv\", sep=',')`\n",
    "- A `new_data` hagan un reindex con las columnas que guardaron el archivo pickle y para los valores `NaN` rellenenlos con un `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ohe = pd.get_dummies(data)\n",
    "data_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./data/categories_ohe.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_ohe.columns, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"./data/new_data.csv\", sep=\",\", encoding='ISO-8859-1') \n",
    "with open('./data/categories_ohe.pickle', 'rb') as handle:\n",
    "    ohe_tr = pickle.load(handle)\n",
    "\n",
    "new_data = pd.get_dummies(new_data).reindex(columns = ohe_tr, fill_value=0)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 游늸 Consigna 3\n",
    "\n",
    "Cargar su notebook y datasets a un repositorio p칰blico personal y compartirlo por Discord.\n",
    "<br>Consideren usar git lfs para los dataset con extensi칩n csv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
